{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(\"../TAMU_FINAL_DATASET_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the numeric data\n",
    "df = data_file.select_dtypes(include=['float64','int64'])\n",
    "categorical_data = data_file.select_dtypes(exclude=['float64','int64'])\n",
    "categorical_df = pd.DataFrame()\n",
    "for column in categorical_data.columns:\n",
    "    dummies = pd.get_dummies(categorical_data[column], prefix=column)\n",
    "    categorical_df = pd.concat([categorical_df, dummies], axis=1)\n",
    "#df = pd.concat([df['AMI_FLAG'], categorical_df], axis=1)\n",
    "df = pd.concat([df, categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 469)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2726, 469)\n",
      "(2726, 469)\n",
      "(5452, 469)\n",
      "(4040, 469)\n",
      "(4040, 468)\n",
      "(4040,)\n"
     ]
    }
   ],
   "source": [
    "sum(df['AMI_FLAG'] == 1)\n",
    "df_AMI = df[df['AMI_FLAG'] == 1]\n",
    "df_NOAMI = df[df['AMI_FLAG'] == 0]\n",
    "df_NOAMI_sample = df_NOAMI.sample(2726)\n",
    "print(df_AMI.shape)\n",
    "print(df_NOAMI_sample.shape)\n",
    "\n",
    "\n",
    "df = pd.concat([df_AMI, df_NOAMI_sample], axis = 0)\n",
    "# drop the null value \n",
    "\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "# define the target we would like to predict \n",
    "y = df['AMI_FLAG']\n",
    "\n",
    "X = df.loc[:, df.columns != 'AMI_FLAG']\n",
    "\n",
    "# sanity check on X, y dimensions \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  Tensor(\"Placeholder:0\", shape=(?, 468), dtype=float32)\n",
      "logits:  Tensor(\"fully_connected/Elu:0\", shape=(?, 128), dtype=float32)\n",
      "loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "predicted_labels:  Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# modeling \n",
    "\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 468])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "\n",
    "\n",
    "# tanh, elu, selu, softplus, and softsign\n",
    "\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.relu)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.tanh)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.selu)\n",
    "\n",
    "\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.softplus)\n",
    "logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.elu)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(\"x: \", x)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(201):\n",
    "        #print('EPOCH', i)\n",
    "        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: X_train, y: y_train})\n",
    "        if i % 50 == 0:\n",
    "            print(\"Loss: \", loss)\n",
    "        #print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_train})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_train, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.510\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_test})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_test, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6079460269865068\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fitting data\n",
      "1.0\n",
      "0.4917541229385307\n"
     ]
    }
   ],
   "source": [
    "# try some other sklearn model here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('finish fitting data')\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00289259 0.0039376  0.00043894 0.05731346 0.07990643 0.\n",
      " 0.         0.00102756 0.0033593  0.         0.00153819 0.\n",
      " 0.0033882  0.         0.         0.00064987 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00036454 0.00179876 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00403502\n",
      " 0.00795568 0.00023798 0.         0.00140605 0.00753876 0.\n",
      " 0.         0.         0.         0.         0.00087898 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00059974 0.00142143 0.0048986  0.00288857 0.\n",
      " 0.         0.         0.00437133 0.00243041 0.0097332  0.0063828\n",
      " 0.00412831 0.00677299 0.00581217 0.00341202 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00578643 0.         0.         0.00171221 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00106067 0.         0.\n",
      " 0.         0.00081173 0.00255651 0.         0.00188873 0.\n",
      " 0.         0.         0.         0.01036502 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00028905 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00155176 0.         0.         0.\n",
      " 0.         0.01516504 0.         0.         0.00137658 0.0232069\n",
      " 0.         0.00254036 0.00335921 0.         0.00700472 0.00914432\n",
      " 0.         0.00695464 0.00301185 0.         0.02124228 0.\n",
      " 0.         0.         0.01520222 0.00217012 0.         0.00293715\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0014561  0.         0.         0.\n",
      " 0.00085539 0.00017999 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.0011518  0.         0.00753849\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00127429 0.         0.\n",
      " 0.         0.         0.00299596 0.011207   0.00415338 0.00116159\n",
      " 0.00180523 0.0012878  0.         0.         0.00085836 0.02195082\n",
      " 0.00053452 0.0011472  0.         0.         0.00196465 0.\n",
      " 0.00453132 0.0012765  0.         0.         0.         0.\n",
      " 0.         0.00555237 0.         0.         0.0226438  0.04730064\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01653493 0.         0.00037274 0.\n",
      " 0.0011852  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.0012664  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07016288 0.06803938 0.02948241 0.02007302 0.05052286 0.06013307\n",
      " 0.         0.         0.         0.01486003 0.01027065 0.\n",
      " 0.0124692  0.04993439 0.         0.01005774 0.         0.03040369\n",
      " 0.01084796 0.00333829 0.         0.         0.         0.\n",
      " 0.         0.00098973 0.         0.         0.         0.\n",
      " 0.         0.00058359 0.00112035 0.         0.00150342 0.\n",
      " 0.00291186 0.         0.00108057 0.00162217 0.         0.00110056\n",
      " 0.         0.         0.         0.00101633 0.00282062 0.\n",
      " 0.0032736  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00142365 0.         0.00115553 0.00474536\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00101361 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "0.6847745750184775\n",
      "0.6416791604197901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, criterion='entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = clf.feature_importances_\n",
    "extractedIdx = np.nonzero(important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   7,   8,  10,  12,  15,  25,  26,  35,\n",
       "         36,  37,  39,  40,  46,  55,  56,  57,  58,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  79,  82,  93,  97,  98, 100, 105, 118, 134,\n",
       "        139, 142, 143, 145, 146, 148, 149, 151, 152, 154, 158, 159, 161,\n",
       "        170, 174, 175, 219, 221, 291, 296, 297, 298, 299, 300, 301, 304,\n",
       "        305, 306, 307, 310, 312, 313, 319, 322, 323, 332, 334, 336, 346,\n",
       "        378, 379, 380, 381, 382, 383, 387, 388, 390, 391, 393, 395, 396,\n",
       "        397, 403, 409, 410, 412, 414, 416, 417, 419, 423, 424, 426, 434,\n",
       "        436, 437, 458]),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(extractedIdx[0]))\n",
    "extractedIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "df.columns[0]\n",
    "extracted_name = []\n",
    "for idx in extractedIdx:\n",
    "    extracted_name.append(df.columns[idx])\n",
    "\n",
    "print(len(extracted_name[0]))\n",
    "lst = list(extracted_name[0])\n",
    "newDF = df[lst].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AMI_FLAG</th>\n",
       "      <th>ORIG_REAS_ENTITLE_CD</th>\n",
       "      <th>RECON_MA_RISK_SCORE_NBR</th>\n",
       "      <th>CON_VISIT_04_Q02</th>\n",
       "      <th>CON_VISIT_04_Q03</th>\n",
       "      <th>CON_VISIT_21_Q01</th>\n",
       "      <th>CON_VISIT_21_Q03</th>\n",
       "      <th>CON_VISIT_05_Q02</th>\n",
       "      <th>...</th>\n",
       "      <th>Index_Health_ins_engage</th>\n",
       "      <th>Index_Health_ins_influence</th>\n",
       "      <th>Population_density_centile_US</th>\n",
       "      <th>CDC_NPH_GAP</th>\n",
       "      <th>CDC_EYE_GAP</th>\n",
       "      <th>BCS_GAP</th>\n",
       "      <th>ACE_ELIG</th>\n",
       "      <th>STATIN_ELIG</th>\n",
       "      <th>SEX_CD_F</th>\n",
       "      <th>Diab_Type_Diabetes Type I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50063.227475</td>\n",
       "      <td>74.558416</td>\n",
       "      <td>0.493069</td>\n",
       "      <td>0.269802</td>\n",
       "      <td>1.375350</td>\n",
       "      <td>0.536386</td>\n",
       "      <td>0.512376</td>\n",
       "      <td>0.843317</td>\n",
       "      <td>0.832426</td>\n",
       "      <td>0.105446</td>\n",
       "      <td>...</td>\n",
       "      <td>2.356436</td>\n",
       "      <td>3.028465</td>\n",
       "      <td>58.892079</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>0.104950</td>\n",
       "      <td>0.051238</td>\n",
       "      <td>0.490594</td>\n",
       "      <td>0.476733</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>0.036634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28931.487039</td>\n",
       "      <td>9.302996</td>\n",
       "      <td>0.500014</td>\n",
       "      <td>0.447799</td>\n",
       "      <td>1.114341</td>\n",
       "      <td>1.871897</td>\n",
       "      <td>1.545656</td>\n",
       "      <td>2.667597</td>\n",
       "      <td>2.426516</td>\n",
       "      <td>0.720561</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176692</td>\n",
       "      <td>2.385259</td>\n",
       "      <td>25.943360</td>\n",
       "      <td>0.125834</td>\n",
       "      <td>0.306528</td>\n",
       "      <td>0.220509</td>\n",
       "      <td>0.499973</td>\n",
       "      <td>0.499520</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>0.187884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24925.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50392.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75201.500000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.735500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99978.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.385000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID          AGE     AMI_FLAG  ORIG_REAS_ENTITLE_CD  \\\n",
       "count   4040.000000  4040.000000  4040.000000           4040.000000   \n",
       "mean   50063.227475    74.558416     0.493069              0.269802   \n",
       "std    28931.487039     9.302996     0.500014              0.447799   \n",
       "min       14.000000    40.000000     0.000000              0.000000   \n",
       "25%    24925.500000    69.000000     0.000000              0.000000   \n",
       "50%    50392.500000    74.000000     0.000000              0.000000   \n",
       "75%    75201.500000    81.000000     1.000000              1.000000   \n",
       "max    99978.000000    95.000000     1.000000              3.000000   \n",
       "\n",
       "       RECON_MA_RISK_SCORE_NBR  CON_VISIT_04_Q02  CON_VISIT_04_Q03  \\\n",
       "count              4040.000000       4040.000000       4040.000000   \n",
       "mean                  1.375350          0.536386          0.512376   \n",
       "std                   1.114341          1.871897          1.545656   \n",
       "min                   0.000000          0.000000          0.000000   \n",
       "25%                   0.640000          0.000000          0.000000   \n",
       "50%                   1.032000          0.000000          0.000000   \n",
       "75%                   1.735500          1.000000          1.000000   \n",
       "max                  11.385000         65.000000         28.000000   \n",
       "\n",
       "       CON_VISIT_21_Q01  CON_VISIT_21_Q03  CON_VISIT_05_Q02  \\\n",
       "count       4040.000000       4040.000000       4040.000000   \n",
       "mean           0.843317          0.832426          0.105446   \n",
       "std            2.667597          2.426516          0.720561   \n",
       "min            0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000   \n",
       "75%            0.000000          0.000000          0.000000   \n",
       "max           51.000000         35.000000         13.000000   \n",
       "\n",
       "                 ...              Index_Health_ins_engage  \\\n",
       "count            ...                          4040.000000   \n",
       "mean             ...                             2.356436   \n",
       "std              ...                             2.176692   \n",
       "min              ...                             0.000000   \n",
       "25%              ...                             1.000000   \n",
       "50%              ...                             2.000000   \n",
       "75%              ...                             3.000000   \n",
       "max              ...                             9.000000   \n",
       "\n",
       "       Index_Health_ins_influence  Population_density_centile_US  CDC_NPH_GAP  \\\n",
       "count                 4040.000000                    4040.000000  4040.000000   \n",
       "mean                     3.028465                      58.892079     0.016089   \n",
       "std                      2.385259                      25.943360     0.125834   \n",
       "min                      0.000000                       0.000000     0.000000   \n",
       "25%                      1.000000                      38.000000     0.000000   \n",
       "50%                      3.000000                      61.000000     0.000000   \n",
       "75%                      5.000000                      82.000000     0.000000   \n",
       "max                      9.000000                      99.000000     1.000000   \n",
       "\n",
       "       CDC_EYE_GAP      BCS_GAP     ACE_ELIG  STATIN_ELIG     SEX_CD_F  \\\n",
       "count  4040.000000  4040.000000  4040.000000  4040.000000  4040.000000   \n",
       "mean      0.104950     0.051238     0.490594     0.476733     0.517822   \n",
       "std       0.306528     0.220509     0.499973     0.499520     0.499744   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Diab_Type_Diabetes Type I  \n",
       "count                4040.000000  \n",
       "mean                    0.036634  \n",
       "std                     0.187884  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     0.000000  \n",
       "75%                     0.000000  \n",
       "max                     1.000000  \n",
       "\n",
       "[8 rows x 107 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4040, 107)\n",
      "(4040, 107)\n",
      "(4040, 106)\n",
      "(4040,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use only the 107 features, retrain models\n",
    "\n",
    "df = newDF\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "# define the target we would like to predict \n",
    "y = df['AMI_FLAG']\n",
    "\n",
    "X = df.loc[:, df.columns != 'AMI_FLAG']\n",
    "\n",
    "# sanity check on X, y dimensions \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  Tensor(\"Placeholder_34:0\", shape=(?, 106), dtype=float32)\n",
      "logits:  Tensor(\"fully_connected_19/Softplus:0\", shape=(?, 50), dtype=float32)\n",
      "loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n",
      "predicted_labels:  Tensor(\"ArgMax_17:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# modeling \n",
    "\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 106])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "\n",
    "\n",
    "# tanh, elu, selu, softplus, and softsign\n",
    "\n",
    "#logits = tf.contrib.layers.fully_connected(x, 50, tf.nn.elu)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.tanh)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.selu)\n",
    "\n",
    "\n",
    "# this two model has better accuracy -------------\n",
    "\n",
    "logits = tf.contrib.layers.fully_connected(x, 50, tf.nn.relu)\n",
    "logits = tf.contrib.layers.fully_connected(x, 50, tf.nn.softplus)\n",
    "\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(\"x: \", x)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean_34:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(201):\n",
    "        #print('EPOCH', i)\n",
    "        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: X_train, y: y_train})\n",
    "        if i % 50 == 0:\n",
    "            print(\"Loss: \", loss)\n",
    "        #print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_train})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_train, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_test})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_test, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5472263868065967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fitting data\n",
      "1.0\n",
      "0.49250374812593706\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('finish fitting data')\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00076343 0.05192551 0.         0.0930434  0.         0.00184984\n",
      " 0.         0.         0.00063242 0.         0.00456323 0.00211605\n",
      " 0.00164865 0.02511586 0.         0.         0.         0.\n",
      " 0.         0.         0.00845447 0.00108493 0.00187023 0.\n",
      " 0.00320354 0.0075394  0.0053885  0.0064146  0.01584575 0.00153646\n",
      " 0.         0.00065686 0.         0.00652982 0.         0.0035972\n",
      " 0.         0.         0.00401855 0.         0.00411384 0.\n",
      " 0.00542829 0.         0.00822809 0.00042279 0.0100366  0.00033866\n",
      " 0.         0.03737866 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00577827 0.00539838\n",
      " 0.02637311 0.         0.00060563 0.00439411 0.00314754 0.0341734\n",
      " 0.00311063 0.00032447 0.         0.00405149 0.         0.00041658\n",
      " 0.02125726 0.00024506 0.         0.         0.         0.\n",
      " 0.13021067 0.10675221 0.04512861 0.04430996 0.10976912 0.\n",
      " 0.02583011 0.00121981 0.03333855 0.00080374 0.         0.03203068\n",
      " 0.02298011 0.         0.         0.00056882 0.00882151 0.00966744\n",
      " 0.         0.         0.00319021 0.         0.00061567 0.\n",
      " 0.         0.         0.00174124 0.        ]\n",
      "0.6917960088691796\n",
      "0.6416791604197901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, criterion='entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
