{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(\"../TAMU_FINAL_DATASET_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the numeric data\n",
    "df = data_file.select_dtypes(include=['float64','int64'])\n",
    "categorical_data = data_file.select_dtypes(exclude=['float64','int64'])\n",
    "categorical_df = pd.DataFrame()\n",
    "for column in categorical_data.columns:\n",
    "    dummies = pd.get_dummies(categorical_data[column], prefix=column)\n",
    "    categorical_df = pd.concat([categorical_df, dummies], axis=1)\n",
    "#df = pd.concat([df['AMI_FLAG'], categorical_df], axis=1)\n",
    "df = pd.concat([df, categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 469)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2726, 469)\n",
      "(2726, 469)\n",
      "(5452, 469)\n",
      "(4042, 469)\n",
      "(4042, 468)\n",
      "(4042,)\n"
     ]
    }
   ],
   "source": [
    "sum(df['AMI_FLAG'] == 1)\n",
    "df_AMI = df[df['AMI_FLAG'] == 1]\n",
    "df_NOAMI = df[df['AMI_FLAG'] == 0]\n",
    "df_NOAMI_sample = df_NOAMI.sample(2726)\n",
    "print(df_AMI.shape)\n",
    "print(df_NOAMI_sample.shape)\n",
    "\n",
    "\n",
    "df = pd.concat([df_AMI, df_NOAMI_sample], axis = 0)\n",
    "# drop the null value \n",
    "\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "# define the target we would like to predict \n",
    "y = df['AMI_FLAG']\n",
    "\n",
    "X = df.loc[:, df.columns != 'AMI_FLAG']\n",
    "\n",
    "# sanity check on X, y dimensions \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  Tensor(\"Placeholder:0\", shape=(?, 468), dtype=float32)\n",
      "logits:  Tensor(\"fully_connected/Elu:0\", shape=(?, 128), dtype=float32)\n",
      "loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "predicted_labels:  Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# modeling \n",
    "\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 468])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "\n",
    "\n",
    "# tanh, elu, selu, softplus, and softsign\n",
    "\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.relu)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.tanh)\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.selu)\n",
    "\n",
    "\n",
    "#logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.softplus)\n",
    "logits = tf.contrib.layers.fully_connected(x, 128, tf.nn.elu)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(\"x: \", x)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(201):\n",
    "        #print('EPOCH', i)\n",
    "        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: X_train, y: y_train})\n",
    "        if i % 50 == 0:\n",
    "            print(\"Loss: \", loss)\n",
    "        #print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_train})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_train, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted = sess.run([correct_pred], feed_dict={x: X_test})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_test, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some other sklearn model here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('finish fitting data')\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.02462455 0.         0.04369402 0.04999585 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00304791 0.01717337 0.         0.         0.         0.\n",
      " 0.00105303 0.         0.         0.00319535 0.00150197 0.\n",
      " 0.         0.00312999 0.         0.00083371 0.         0.\n",
      " 0.00072983 0.         0.         0.00221513 0.         0.00175937\n",
      " 0.01584784 0.00206072 0.         0.         0.01020055 0.0004557\n",
      " 0.         0.         0.         0.         0.00040789 0.00207858\n",
      " 0.         0.         0.         0.01667739 0.         0.\n",
      " 0.         0.         0.         0.00250473 0.00178289 0.\n",
      " 0.         0.         0.00087815 0.00414516 0.         0.00643278\n",
      " 0.         0.00169373 0.00988335 0.00370312 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00090298 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01234607 0.00270051 0.         0.         0.\n",
      " 0.         0.         0.00289194 0.00763766 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00104781 0.         0.         0.         0.\n",
      " 0.00710953 0.02202499 0.00308799 0.         0.00187376 0.01447467\n",
      " 0.         0.00118862 0.00249481 0.00202787 0.01234213 0.01550568\n",
      " 0.         0.0074111  0.00874015 0.00107534 0.02608403 0.\n",
      " 0.         0.         0.00523815 0.00466749 0.         0.004521\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0053011  0.         0.         0.\n",
      " 0.00744779 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00081327 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00313626 0.00246143 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00070343 0.         0.00119024 0.00143159 0.\n",
      " 0.         0.         0.00392344 0.00535643 0.00363616 0.\n",
      " 0.         0.00120242 0.00035829 0.         0.         0.01272107\n",
      " 0.00103397 0.         0.         0.         0.         0.00108217\n",
      " 0.00364958 0.         0.         0.         0.         0.00069151\n",
      " 0.         0.00462613 0.         0.         0.04205064 0.02398002\n",
      " 0.         0.         0.         0.         0.00128045 0.\n",
      " 0.         0.         0.00786238 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00135668 0.\n",
      " 0.         0.00120048 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05878041 0.06630861 0.04760533 0.01253901 0.06716919 0.04143663\n",
      " 0.00190424 0.         0.         0.03616142 0.03394254 0.00114015\n",
      " 0.00292945 0.03535906 0.         0.0037481  0.         0.00397517\n",
      " 0.01086793 0.00138242 0.00120021 0.         0.         0.\n",
      " 0.         0.00183534 0.         0.         0.         0.\n",
      " 0.         0.         0.00027123 0.         0.00298006 0.\n",
      " 0.         0.         0.         0.00173675 0.00072961 0.\n",
      " 0.         0.         0.         0.         0.00563644 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00388311 0.\n",
      " 0.00031624 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00107602 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01748744 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "0.691285081240768\n",
      "0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, criterion='entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5937031484257871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
