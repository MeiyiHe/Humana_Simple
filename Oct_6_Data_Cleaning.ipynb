{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import impyute as impy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_file = pd.read_csv(\"../TAMU_FINAL_DATASET_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process categroical variable\n",
    "def catogrical_var_onehot(data_file):\n",
    "    categorical_data = data_file.select_dtypes(exclude=['float64','int64'])\n",
    "    categorical_df = pd.DataFrame()\n",
    "    for column in categorical_data.columns:\n",
    "        dummies = pd.get_dummies(categorical_data[column], prefix=column)\n",
    "        categorical_df = pd.concat([categorical_df, dummies], axis=1)\n",
    "    return categorical_df\n",
    "\n",
    "# Process numerical variable\n",
    "def numerical_var(data_file):\n",
    "    numerical_df = data_file.select_dtypes(include=['float64','int64'])\n",
    "    return numerical_df\n",
    "\n",
    "# Compute na values\n",
    "def fill_na(df):\n",
    "    df_column = df.columns\n",
    "    df_nona = impy.mice(df.values)\n",
    "    df_nona = pd.DataFrame(df_nona, columns=df_column)\n",
    "    return df_nona\n",
    "\n",
    "whole_df = pd.concat([numerical_var(data_file), catogrical_var_onehot(data_file)], axis=1)\n",
    "whole_df = fill_na(whole_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726, 469)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~2700 AMIFLAG = 1 entries and same amount of flag = 0\n",
    "def balanced_data(df):\n",
    "    df_AMI = df[df['AMI_FLAG'] == 1]\n",
    "    df_NOAMI_sample = df_NOAMI.sample(df_AMI.shape[0])\n",
    "    balanced_df = pd.concat([df_AMI, df_NOAMI_sample], axis = 0)\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = balanced_data(df)\n",
    "\n",
    "balanced_df[balanced_df['AMI_FLAG'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3652, 468)\n"
     ]
    }
   ],
   "source": [
    "def train_test_set(df):\n",
    "    X = df.loc[:, df.columns != 'AMI_FLAG']\n",
    "    y = df['AMI_FLAG']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)\n",
    "    return_dic = {'X_train':X_train, 'X_test':X_test, 'y_train':y_train, 'y_test':y_test}\n",
    "    return return_dic\n",
    "\n",
    "whole_suite = train_test_set(whole_df)\n",
    "balanced_suite = train_test_set(balanced_df)\n",
    "\n",
    "print(balanced_suite['X_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_model(suite):\n",
    "    # construct linear model using sklearn \n",
    "    lm = LogisticRegression(penalty='l1')\n",
    "    model = lm.fit(suite['X_train'], suite['y_train'])\n",
    "    return model\n",
    "    \n",
    "def rf_model(suite):\n",
    "    clf = RandomForestClassifier(n_estimators=300,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_samples_split=10,\n",
    "                                max_depth=10,\n",
    "                                max_features='log2',\n",
    "                                criterion='entropy')\n",
    "    model = clf.fit(suite['X_train'], suite['y_train'])\n",
    "    return model\n",
    "    \n",
    "def test_on(X, model, y):\n",
    "    pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    print(\"Accuracy is: \" + str(accuracy))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.746089552238806\n",
      "Accuracy is: 0.7402424242424243\n"
     ]
    }
   ],
   "source": [
    "log_model = logistic_model(balanced_suite)\n",
    "rf_model = rf_model(balanced_suite)\n",
    "test_on(whole_suite['X_train'], rf_model, whole_suite['y_train'])\n",
    "test_on(whole_suite['X_test'], rf_model, whole_suite['y_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
