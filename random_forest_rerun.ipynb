{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(\"../TAMU_FINAL_DATASET_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the numeric data\n",
    "df = data_file.select_dtypes(include=['float64','int64'])\n",
    "categorical_data = data_file.select_dtypes(exclude=['float64','int64'])\n",
    "categorical_df = pd.DataFrame()\n",
    "for column in categorical_data.columns:\n",
    "    dummies = pd.get_dummies(categorical_data[column], prefix=column)\n",
    "    categorical_df = pd.concat([categorical_df, dummies], axis=1)\n",
    "#df = pd.concat([df['AMI_FLAG'], categorical_df], axis=1)\n",
    "df = pd.concat([df, categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 469)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2726, 469)\n",
      "(2726, 469)\n",
      "\n",
      "(5452, 469)\n",
      "(4046, 469)\n",
      "(4046, 468)\n",
      "(4046,)\n"
     ]
    }
   ],
   "source": [
    "sum(df['AMI_FLAG'] == 1)\n",
    "df_AMI = df[df['AMI_FLAG'] == 1]\n",
    "df_NOAMI = df[df['AMI_FLAG'] == 0]\n",
    "df_NOAMI_sample = df_NOAMI.sample(2726)\n",
    "print(df_AMI.shape)\n",
    "print(df_NOAMI_sample.shape)\n",
    "\n",
    "print()\n",
    "df = pd.concat([df_AMI, df_NOAMI_sample], axis = 0)\n",
    "# drop the null value \n",
    "\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "# define the target we would like to predict \n",
    "y = df['AMI_FLAG']\n",
    "\n",
    "X = df.loc[:, df.columns != 'AMI_FLAG']\n",
    "\n",
    "# sanity check on X, y dimensions \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0015167  0.01856772 0.         0.04939601 0.0696136  0.\n",
      " 0.         0.00055299 0.         0.00137255 0.00166588 0.\n",
      " 0.         0.00706298 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00102868 0.\n",
      " 0.         0.00052627 0.00069404 0.00097734 0.00069108 0.\n",
      " 0.         0.         0.         0.00149607 0.         0.\n",
      " 0.02109182 0.00061883 0.00359131 0.00014588 0.00209989 0.00053506\n",
      " 0.00182501 0.         0.         0.00038027 0.         0.00263514\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00305207 0.         0.00040546 0.         0.\n",
      " 0.         0.00089532 0.00947466 0.00529799 0.         0.01295141\n",
      " 0.         0.         0.         0.00162835 0.         0.\n",
      " 0.         0.         0.         0.         0.000988   0.\n",
      " 0.         0.01116582 0.         0.         0.         0.\n",
      " 0.00152773 0.         0.         0.         0.         0.00166392\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00063279 0.01689495 0.00335847 0.         0.         0.\n",
      " 0.         0.         0.00620719 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00037358 0.         0.00044746 0.         0.\n",
      " 0.00356126 0.00956038 0.         0.         0.         0.0134671\n",
      " 0.         0.         0.00432013 0.00526739 0.00369419 0.01080725\n",
      " 0.00360118 0.00428019 0.         0.         0.01097512 0.\n",
      " 0.         0.         0.01709396 0.         0.         0.\n",
      " 0.         0.         0.         0.00206708 0.         0.\n",
      " 0.         0.         0.00146793 0.         0.         0.\n",
      " 0.         0.00147485 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00038805\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00199689 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00134243\n",
      " 0.         0.         0.00348367 0.01117275 0.00069086 0.00051943\n",
      " 0.         0.         0.         0.         0.00054127 0.01030228\n",
      " 0.0058301  0.         0.         0.         0.         0.\n",
      " 0.00646582 0.         0.         0.         0.         0.\n",
      " 0.         0.00350663 0.         0.         0.04844077 0.01765026\n",
      " 0.         0.         0.         0.         0.00164173 0.\n",
      " 0.         0.         0.01246046 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00096733 0.\n",
      " 0.         0.00325983 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09498745 0.05108523 0.02367209 0.01177919 0.06456318 0.05544276\n",
      " 0.01189069 0.         0.         0.04890314 0.00979804 0.\n",
      " 0.0197983  0.04226031 0.         0.01572696 0.         0.01451992\n",
      " 0.00818622 0.0020064  0.         0.         0.         0.\n",
      " 0.00407878 0.00067757 0.00073115 0.         0.00152943 0.\n",
      " 0.         0.         0.         0.00186283 0.00199353 0.0007366\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00112062 0.         0.         0.00281171 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00675075 0.00147107\n",
      " 0.         0.         0.         0.         0.         0.00052973\n",
      " 0.         0.         0.00070947 0.         0.         0.\n",
      " 0.00067832 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0119233  0.         0.         0.\n",
      " 0.00042638 0.         0.         0.         0.         0.        ]\n",
      "0.7077490774907749\n",
      "0.6347305389221557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, criterion='entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = clf.feature_importances_\n",
    "extractedIdx = np.nonzero(important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   3,   4,   7,   9,  10,  13,  22,  25,  26,  27,  28,\n",
       "         33,  36,  37,  38,  39,  40,  41,  42,  45,  47,  55,  57,  61,\n",
       "         62,  63,  65,  69,  76,  79,  84,  89,  96,  97,  98, 104, 133,\n",
       "        135, 138, 139, 143, 146, 147, 148, 149, 150, 151, 154, 158, 165,\n",
       "        170, 175, 215, 223, 293, 296, 297, 298, 299, 304, 305, 306, 312,\n",
       "        319, 322, 323, 328, 332, 346, 349, 378, 379, 380, 381, 382, 383,\n",
       "        384, 387, 388, 390, 391, 393, 395, 396, 397, 402, 403, 404, 406,\n",
       "        411, 412, 413, 421, 424, 436, 437, 443, 446, 450, 458, 462]),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(extractedIdx[0]))\n",
    "extractedIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[0])\n",
    "extracted_name = []\n",
    "for idx in extractedIdx:\n",
    "    extracted_name.append(df.columns[idx])\n",
    "\n",
    "print(len(extracted_name[0]))\n",
    "lst = list(extracted_name[0])\n",
    "newDF = df[lst].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'AGE', 'ORIG_REAS_ENTITLE_CD', 'RECON_MA_RISK_SCORE_NBR',\n",
      "       'CON_VISIT_04_Q02', 'CON_VISIT_04_Q04', 'CON_VISIT_21_Q01',\n",
      "       'CON_VISIT_03_Q02', 'CON_VISIT_24_Q02', 'CON_VISIT_30_Q04',\n",
      "       ...\n",
      "       'Home_value', 'CDC_HBATEST_GAP', 'CDC_EYE_GAP', 'STATIN_ELIG',\n",
      "       'SEX_CD_F', 'PCP_ASSIGNMENT_ATTRIBUTED', 'DUAL_N', 'LIS_N',\n",
      "       'Diab_Type_Diabetes Type I', 'Dwelling_Type_B'],\n",
      "      dtype='object', length=103)\n"
     ]
    }
   ],
   "source": [
    "print(newDF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 103)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 469)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_y = df['AMI_FLAG']\n",
    "half_X = newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_X_train, half_X_test, half_y_train, half_y_test = train_test_split(half_X, half_y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74762, 469)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on the whole dataset\n",
    "\n",
    "origDF = data_file.select_dtypes(include=['float64','int64'])\n",
    "categorical_data = data_file.select_dtypes(exclude=['float64','int64'])\n",
    "categorical_df = pd.DataFrame()\n",
    "for column in categorical_data.columns:\n",
    "    dummies = pd.get_dummies(categorical_data[column], prefix=column)\n",
    "    categorical_df = pd.concat([categorical_df, dummies], axis=1)\n",
    "#df = pd.concat([df['AMI_FLAG'], categorical_df], axis=1)\n",
    "origDF = pd.concat([origDF, categorical_df], axis=1)\n",
    "\n",
    "origDF = origDF.dropna()\n",
    "\n",
    "origDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "orig_y = origDF['AMI_FLAG']\n",
    "\n",
    "\n",
    "print(origDF.columns[0])\n",
    "print(len(extracted_name[0]))\n",
    "lst = list(extracted_name[0])\n",
    "origDF = origDF[lst].copy()\n",
    "orig_X = origDF.loc[:, origDF.columns != 'AMI_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74762, 103)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74762,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_X_train, whole_X_test, whole_y_train, whole_y_test = train_test_split(orig_X, orig_y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 600, \n",
    "                                    min_samples_leaf= 1, \n",
    "                                    min_samples_split= 5, \n",
    "                                    max_depth = None, \n",
    "                                    max_features = 'auto',\n",
    "                                    criterion = 'entropy',\n",
    "                                    bootstrap = True,\n",
    "                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(whole_X_train, whole_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clf = RandomForestClassifier(n_estimators = 600, \n",
    "                                    min_samples_leaf= 1, \n",
    "                                    min_samples_split= 5, \n",
    "                                    max_depth = None, \n",
    "                                    max_features = 'auto',\n",
    "                                    criterion = 'entropy',\n",
    "                                    bootstrap = True,\n",
    "                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_clf.fit(half_X_train, half_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996309963099631\n",
      "0.6504491017964071\n",
      "0.9869435016969454\n",
      "0.9720330739299611\n"
     ]
    }
   ],
   "source": [
    "# balanced classifier, predict on balanced data set\n",
    "half_pred_train = half_clf.predict(half_X_train)\n",
    "half_pred_test = half_clf.predict(half_X_test)\n",
    "print(accuracy_score(half_y_train, half_pred_train))\n",
    "print(accuracy_score(half_y_test, half_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "# unbalanced classifier, predict on unbalanced data set\n",
    "whole_pred_train = clf.predict(whole_X_train)\n",
    "whole_pred_test = clf.predict(whole_X_test)\n",
    "\n",
    "print(accuracy_score(whole_y_train, whole_pred_train))\n",
    "print(accuracy_score(whole_y_test, whole_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7064284288281094\n",
      "0.7112110894941635\n",
      "0.67380073800738\n",
      "0.655688622754491\n"
     ]
    }
   ],
   "source": [
    "# balanced classifier, predict on unbalanced dataset\n",
    "\n",
    "half_pred_train = half_clf.predict(whole_X_train)\n",
    "half_pred_test = half_clf.predict(whole_X_test)\n",
    "\n",
    "print(accuracy_score(whole_y_train, half_pred_train))\n",
    "print(accuracy_score(whole_y_test, half_pred_test))\n",
    "\n",
    "# unbalanced classifier, predict on balanced dataset\n",
    "whole_pred_train = clf.predict(half_X_train)\n",
    "whole_pred_test = clf.predict(half_X_test)\n",
    "\n",
    "print(accuracy_score(half_y_train, whole_pred_train))\n",
    "print(accuracy_score(half_y_test, whole_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
